{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6998104b",
   "metadata": {},
   "source": [
    "# CSCE 676 — Project Checkpoint 1  \n",
    "## Dataset Comparison, Selection, and EDA (Checkpoint 1)\n",
    "\n",
    "**Student:** Jaehoon Lee  \n",
    "**Date:** 2026-02-11  \n",
    "\n",
    "This notebook identifies three candidate datasets, compares them across required dimensions, selects one dataset, performs exploratory data analysis (EDA), and proposes initial research directions.\n",
    "\n",
    "> **Reproducibility note:** Designed for **Google Colab** (installs packages + streams data).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bb71d3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 0. Collaboration Declaration (Required)\n",
    "\n",
    "On my honor, I declare the following resources were used for this notebook:\n",
    "\n",
    "1. **Collaborators:** None.  \n",
    "2. **Web / Material Sources:**  \n",
    "   - Amazon Reviews'23 website: https://amazon-reviews-2023.github.io/  \n",
    "   - Hugging Face dataset card (Amazon Reviews 2023): https://huggingface.co/datasets/McAuley-Lab/Amazon-Reviews-2023  \n",
    "   - AmazonReviews2023 processing scripts (GitHub): https://github.com/hyp1231/AmazonReviews2023  \n",
    "   - OSHA Accident Search: https://www.osha.gov/ords/imis/accidentsearch.html  \n",
    "   - U.S. DOL Enforcement Data (OSHA): https://enforcedata.dol.gov/  \n",
    "   - NHTSA FARS overview: https://www.nhtsa.gov/research-data/fatality-analysis-reporting-system-fars  \n",
    "   - Data.gov FARS catalog entry: https://catalog.data.gov/dataset/fatality-analysis-reporting-system-fars  \n",
    "3. **AI Tools:** ChatGPT (OpenAI) — used to help draft the comparison write-up, EDA plan, and to structure clean, documented code.  \n",
    "4. **Papers / Citations used:**  \n",
    "   - Hou et al. (2024) *Bridging Language and Items for Retrieval and Recommendation* (linked from the dataset website / HF card).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76d663b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Checkpoint Requirements Map\n",
    "\n",
    "- **(A)** 3 candidate datasets (name/source, course alignment, beyond-course technique, size/structure, types, targets, licensing)  \n",
    "- **(B)** Comparative table (tasks, quality, feasibility, bias, ethics)  \n",
    "- **(C)** Dataset selection + justification + trade-offs  \n",
    "- **(D)** EDA for selected dataset only (basics, cleaning, bias notes)  \n",
    "- **(E)** Initial insights / hypotheses / potential RQs  \n",
    "- **(F)** GitHub repo link (replace placeholder)\n",
    "\n",
    "All algorithmic decisions include a short **WHY** comment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e604b0bd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. (A) Identification of Candidate Datasets (3 candidates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6227a8c4",
   "metadata": {},
   "source": [
    "### Dataset 1 — OSHA Accident / Investigation Narratives (Text + coded fields)\n",
    "\n",
    "- **Dataset name & source:** OSHA Accident Search (incident investigation summaries)  \n",
    "  https://www.osha.gov/ords/imis/accidentsearch.html  \n",
    "  Related portal: https://enforcedata.dol.gov/  \n",
    "- **Course topic alignment:** Text mining; clustering; anomaly detection  \n",
    "- **Beyond-course techniques:** Transformer-based text modeling; topic modeling; information extraction (e.g., causal relation extraction)  \n",
    "- **Size & structure:** Large incident-level records; narratives + structured fields (varies by export)  \n",
    "- **Data types:** Narrative text; dates; industry codes; (possible) injury/severity indicators  \n",
    "- **Target variable(s):** Often unsupervised; possible supervised targets if available (severity/fatality)  \n",
    "- **Licensing/constraints:** Public-facing U.S. government data; handle sensitive narratives carefully and avoid re-identification.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0ec190",
   "metadata": {},
   "source": [
    "### Dataset 2 — Amazon Reviews’23 (McAuley Lab) (Text + User–Item Graph)\n",
    "\n",
    "- **Dataset name & source:** Amazon Reviews 2023  \n",
    "  Website: https://amazon-reviews-2023.github.io/  \n",
    "  Hugging Face: https://huggingface.co/datasets/McAuley-Lab/Amazon-Reviews-2023  \n",
    "  Processing scripts: https://github.com/hyp1231/AmazonReviews2023  \n",
    "- **Course topic alignment:** Text mining; graph mining; clustering/embeddings  \n",
    "- **Beyond-course techniques:** Graph Neural Networks (GNN); transformer-based embeddings/retrieval; topic modeling  \n",
    "- **Size & structure:** Extremely large → requires **streaming/sampling** for feasibility  \n",
    "- **Data types:** user_id, (parent_)asin, rating, text/title, timestamps, helpful votes, verified purchase, metadata fields  \n",
    "- **Target variable(s):** rating/helpfulness prediction; retrieval/recommendation; unsupervised topics/clusters  \n",
    "- **Licensing/constraints:** Follow dataset card / repository terms; be mindful of platform/recommendation bias.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b144b28d",
   "metadata": {},
   "source": [
    "### Dataset 3 — NHTSA FARS (Fatality Analysis Reporting System)\n",
    "\n",
    "- **Dataset name & source:** NHTSA FARS  \n",
    "  https://www.nhtsa.gov/research-data/fatality-analysis-reporting-system-fars  \n",
    "  Data.gov: https://catalog.data.gov/dataset/fatality-analysis-reporting-system-fars  \n",
    "- **Course topic alignment:** Clustering; anomaly detection  \n",
    "- **Beyond-course techniques:** Spatiotemporal modeling; change-point detection; carefully-scoped causal analysis  \n",
    "- **Size & structure:** Large, multi-table relational structure (crash/vehicle/person), yearly releases  \n",
    "- **Data types:** Many coded categorical/ordinal variables + time/location; joins required  \n",
    "- **Target variable(s):** Context class prediction; risk factor modeling (severity variation may be limited in a fatality-only dataset)  \n",
    "- **Licensing/constraints:** Public domain metadata (data.gov); still handle fatality outcomes responsibly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d07dd4e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. (B) Comparative Analysis (Required Table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa6220d",
   "metadata": {},
   "source": [
    "| Dimension | OSHA Narratives | Amazon Reviews’23 | NHTSA FARS |\n",
    "|---|---|---|---|\n",
    "| **Supported tasks (course vs beyond)** | Course: text mining, clustering, anomaly. Beyond: transformers/topic modeling/IE | Course: text + graph + clustering. Beyond: GNN/transformers/topic modeling | Course: clustering/anomaly. Beyond: spatiotemporal modeling |\n",
    "| **Data quality issues** | Noisy narratives; missing fields | Noisy text/spam; category imbalance; huge scale | Multi-table joins; year-to-year schema differences |\n",
    "| **Algorithmic feasibility** | Feasible but acquisition/export can be work | Feasible via streaming/sampling; manageable subgraphs | Feasible with year/variable restrictions |\n",
    "| **Bias considerations** | Reporting/selection bias by industry/time | Recommendation/exposure bias; reviewer self-selection | Geographic/policy/reporting effects |\n",
    "| **Ethical considerations** | Sensitive incident content; re-identification risk | Lower direct harm; still avoid overclaiming | Sensitive fatality outcomes; avoid stigma |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15e259e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. (C) Dataset Selection\n",
    "\n",
    "### **Selected dataset: Amazon Reviews’23 (McAuley Lab)**\n",
    "\n",
    "**Reasons**\n",
    "1. Supports multiple course techniques (text mining, graph-based analysis, clustering/embeddings).  \n",
    "2. Clear beyond-course extension: **GNN embeddings / transformer retrieval** on user–item graphs.  \n",
    "3. Existing tooling (Hugging Face loader + processing scripts) enables a **fully runnable** checkpoint notebook.\n",
    "\n",
    "**Trade-offs**\n",
    "- Not safety-domain specific.  \n",
    "- Scale requires justified sampling/streaming choices.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a0a9e6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. (D) Exploratory Data Analysis (Selected Dataset Only)\n",
    "\n",
    "### EDA plan (what + WHY)\n",
    "1. **Stream + sample** (WHY: full dataset too large for RAM).  \n",
    "2. Optionally filter to **one category** (WHY: interpretability).  \n",
    "3. Compute distributions: ratings, text length, helpful votes, verified purchase.  \n",
    "4. Minimal cleaning: remove empty text, validate rating bounds (WHY: avoid brittle assumptions early).  \n",
    "5. Graph proxy stats: unique users/items + sparsity estimate (WHY: anticipate feasibility for graph/GNN methods).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7745e96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If running in Colab, install dependencies.\n",
    "# WHY: keep the notebook runnable from scratch.\n",
    "\n",
    "!pip -q install datasets pandas numpy matplotlib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7c5994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 5.1 Load via streaming\n",
    "# -----------------------------\n",
    "# WHY streaming: Amazon Reviews'23 is extremely large.\n",
    "DATASET_ID = \"McAuley-Lab/Amazon-Reviews-2023\"\n",
    "SPLIT = \"train\"\n",
    "\n",
    "ds_stream = load_dataset(DATASET_ID, split=SPLIT, streaming=True)\n",
    "ds_stream\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac975a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 5.2 Sample N rows into a DataFrame\n",
    "# -----------------------------\n",
    "# WHY: EDA needs enough rows for distributions but must be feasible in Colab.\n",
    "\n",
    "N_SAMPLE = 20000  # tradeoff between stability and runtime\n",
    "rows = []\n",
    "for i, ex in enumerate(ds_stream):\n",
    "    rows.append(ex)\n",
    "    if i + 1 >= N_SAMPLE:\n",
    "        break\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "print(\"Sampled rows:\", len(df))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a2ddf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.3 Schema inspection\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "df.describe(include=\"all\").T.head(40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0f756f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.4 Minimal cleaning (WHY: required for reliable EDA/text analysis)\n",
    "\n",
    "# Choose a text column robustly\n",
    "text_col_candidates = [c for c in [\"text\", \"review_text\", \"reviewText\"] if c in df.columns]\n",
    "assert len(text_col_candidates) >= 1, \"No recognizable text column found!\"\n",
    "TEXT_COL = text_col_candidates[0]\n",
    "print(\"Using text column:\", TEXT_COL)\n",
    "\n",
    "df[TEXT_COL] = df[TEXT_COL].fillna(\"\").astype(str)\n",
    "before = len(df)\n",
    "df = df[df[TEXT_COL].str.strip().str.len() > 0].copy()\n",
    "print(\"Dropped empty-text rows:\", before - len(df))\n",
    "\n",
    "# Rating validity if present\n",
    "if \"rating\" in df.columns:\n",
    "    df[\"rating\"] = pd.to_numeric(df[\"rating\"], errors=\"coerce\")\n",
    "    before = len(df)\n",
    "    df = df[df[\"rating\"].between(1.0, 5.0, inclusive=\"both\")].copy()\n",
    "    print(\"Dropped invalid-rating rows:\", before - len(df))\n",
    "\n",
    "# Derived features\n",
    "df[\"text_len_chars\"] = df[TEXT_COL].str.len()\n",
    "df[\"text_len_words\"] = df[TEXT_COL].str.split().map(len)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a599ca68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.5 Optional: filter to one category for interpretability (if field exists)\n",
    "\n",
    "category_col_candidates = [c for c in [\"main_category\", \"category\", \"product_category\"] if c in df.columns]\n",
    "CATEGORY_COL = category_col_candidates[0] if category_col_candidates else None\n",
    "print(\"Category column:\", CATEGORY_COL)\n",
    "\n",
    "if CATEGORY_COL is not None:\n",
    "    top_cat = df[CATEGORY_COL].value_counts().index[0]\n",
    "    print(\"Selected category (most frequent in sample):\", top_cat)\n",
    "    df_cat = df[df[CATEGORY_COL] == top_cat].copy()\n",
    "    print(\"Rows in selected category:\", len(df_cat))\n",
    "else:\n",
    "    df_cat = df.copy()\n",
    "    print(\"No category field found; using full sample.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcff8367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.6 EDA: distributions\n",
    "\n",
    "# Rating distribution\n",
    "if \"rating\" in df_cat.columns:\n",
    "    ax = df_cat[\"rating\"].value_counts().sort_index().plot(kind=\"bar\")\n",
    "    ax.set_title(\"Rating Distribution (sample)\")\n",
    "    ax.set_xlabel(\"Rating\")\n",
    "    ax.set_ylabel(\"Count\")\n",
    "    plt.show()\n",
    "\n",
    "# Review length (words)\n",
    "ax = df_cat[\"text_len_words\"].clip(upper=200).plot(kind=\"hist\", bins=50)\n",
    "ax.set_title(\"Review Length (words) — clipped at 200\")\n",
    "ax.set_xlabel(\"Words\")\n",
    "plt.show()\n",
    "\n",
    "# Verified purchase\n",
    "if \"verified_purchase\" in df_cat.columns:\n",
    "    vp = df_cat[\"verified_purchase\"].value_counts(dropna=False)\n",
    "    print(\"Verified purchase counts:\")\n",
    "    display(vp)\n",
    "    print(\"Verified purchase rate:\", (df_cat[\"verified_purchase\"] == True).mean())\n",
    "\n",
    "# Helpful votes\n",
    "if \"helpful_vote\" in df_cat.columns:\n",
    "    hv = pd.to_numeric(df_cat[\"helpful_vote\"], errors=\"coerce\").fillna(0)\n",
    "    print(\"Helpful vote summary:\")\n",
    "    display(hv.describe())\n",
    "    ax = hv.clip(upper=50).plot(kind=\"hist\", bins=50)\n",
    "    ax.set_title(\"Helpful Votes — clipped at 50\")\n",
    "    ax.set_xlabel(\"Votes\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ac00ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.7 Graph feasibility proxy: user–item sparsity estimate (sample)\n",
    "\n",
    "item_col_candidates = [c for c in [\"parent_asin\", \"asin\", \"item_id\"] if c in df_cat.columns]\n",
    "assert len(item_col_candidates) >= 1, \"No recognizable item ID column found!\"\n",
    "ITEM_COL = item_col_candidates[0]\n",
    "print(\"Using item ID column:\", ITEM_COL)\n",
    "\n",
    "user_col_candidates = [c for c in [\"user_id\", \"reviewerID\", \"user\"] if c in df_cat.columns]\n",
    "assert len(user_col_candidates) >= 1, \"No recognizable user ID column found!\"\n",
    "USER_COL = user_col_candidates[0]\n",
    "print(\"Using user ID column:\", USER_COL)\n",
    "\n",
    "n_users = df_cat[USER_COL].nunique()\n",
    "n_items = df_cat[ITEM_COL].nunique()\n",
    "n_edges = len(df_cat)\n",
    "\n",
    "density_est = n_edges / (n_users * n_items) if (n_users * n_items) > 0 else np.nan\n",
    "\n",
    "print(f\"Unique users: {n_users:,}\")\n",
    "print(f\"Unique items: {n_items:,}\")\n",
    "print(f\"Interactions (edges): {n_edges:,}\")\n",
    "print(f\"User–item density estimate (sample): {density_est:.6e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1f503c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Tests / Sanity Checks (Required)\n",
    "\n",
    "Simple assertion-based checks to validate:\n",
    "- expected columns exist (text/user/item)\n",
    "- cleaning invariants (no empty text; ratings in [1,5])\n",
    "- derived features are valid\n",
    "- sparsity estimate is finite\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43933ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "print(\"Running EDA sanity checks...\")\n",
    "\n",
    "assert (df_cat[TEXT_COL].str.strip().str.len() > 0).all(), \"Empty text found after cleaning!\"\n",
    "assert (df_cat[\"text_len_words\"] >= 0).all(), \"Negative word length detected!\"\n",
    "assert (df_cat[\"text_len_chars\"] >= 0).all(), \"Negative char length detected!\"\n",
    "\n",
    "if \"rating\" in df_cat.columns:\n",
    "    assert df_cat[\"rating\"].between(1.0, 5.0, inclusive=\"both\").all(), \"Rating outside [1,5] found!\"\n",
    "\n",
    "assert df_cat[USER_COL].notna().any(), \"No user IDs found!\"\n",
    "assert df_cat[ITEM_COL].notna().any(), \"No item IDs found!\"\n",
    "assert df_cat[USER_COL].nunique() > 10, \"Too few unique users; sampling may be broken.\"\n",
    "assert df_cat[ITEM_COL].nunique() > 10, \"Too few unique items; sampling may be broken.\"\n",
    "\n",
    "assert math.isfinite(float(density_est)), \"Density estimate is not finite!\"\n",
    "\n",
    "print(\"All EDA sanity checks passed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a033de7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Bias & Ethical Considerations (Selected Dataset)\n",
    "\n",
    "**Potential biases**\n",
    "- **Reviewer self-selection:** reviewers are not representative of all buyers.  \n",
    "- **Exposure/recommendation bias:** visible products get more reviews.  \n",
    "- **Category imbalance:** patterns may not generalize.\n",
    "\n",
    "**Ethics**\n",
    "- Avoid releasing any identifying user information; report aggregate stats.\n",
    "- Avoid overclaiming causal effects from observational review data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdb75ce",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. (E) Initial Insights and Direction\n",
    "\n",
    "After running EDA, use your observed plots/stats to fill in specifics.\n",
    "\n",
    "### Likely observations\n",
    "- Ratings are often skewed toward high values (positivity bias).  \n",
    "- Review lengths are long-tailed (many short reviews, few very long).  \n",
    "- User–item interactions are sparse, suggesting graph-based models must handle sparsity.\n",
    "\n",
    "### Hypotheses\n",
    "1. Text-derived topics may explain variance beyond rating alone (e.g., shipping vs durability).  \n",
    "2. GNN item embeddings may capture similarity beyond text-only embeddings by leveraging multi-hop connectivity.\n",
    "\n",
    "### Potential research questions (RQs)\n",
    "1. How do **topic clusters** (from review text) relate to rating distributions within a category?  \n",
    "2. Do **GNN-based item embeddings** improve retrieval/similarity vs text-only embeddings?  \n",
    "3. Can we detect **anomalous/spam-like review patterns** using text length, helpfulness, and temporal features?\n",
    "\n",
    "### Beyond-course technique target\n",
    "- **Graph Neural Networks (GNN)** for user–item embedding learning (beyond course).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9b02df",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. (F) GitHub Portfolio Link (Required)\n",
    "\n",
    "**Public GitHub repository (replace placeholder):**  \n",
    "- https://github.com/<YOUR_USERNAME>/csce676-project\n",
    "\n",
    "Include in the repo:\n",
    "- This notebook (fully run)\n",
    "- A short `README.md` describing dataset, course + beyond-course techniques, and how to run.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
